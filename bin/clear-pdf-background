#! /usr/bin/env bash

set -e

script_name="$(basename "$0")"

usage_msg="Generate a copy of 'source_pdf' with flat background color replaced by transparency on each page.

Depends on several CLI tools being installed.

Note that the resulting PDF may be *much* larger, as it converts the PDF pages
to PNGs. That solves the otherwise-impracticable problem of 'editing PDFs', at
the cost of losing the benefits of vector-based PDFs.

Usage: $script_name <source_pdf> <result_pdf>"

if [ $# -ne 2 ]; then
    echo "$usage_msg

You must pass the path to the source PDF!" >&2

    exit 1
fi

if ! [[ "$1" = *.pdf ]]; then
    echo "'$1' does not end in '.pdf'!" >&2

    exit 1
fi

if [ -f "$2" ]; then
    echo "'$2' already exists!" >&2

    exit 1
fi

# TODO Check that file actually *is* a PDF, maybe with `file` command
source_pdf="$1"
result_pdf="$2"

# Should create temporary directory on macOS or Linux, according to
# https://unix.stackexchange.com/a/84980.
tmpdir=$(mktemp -d 2>/dev/null || mktemp -d -t '')
echo "Created temporary working directory at '$tmpdir'" >&2

# FIXME Split the input PDF into individual pages.
tmp_pages_dir="$tmpdir/pages"
mkdir -p "$tmp_pages_dir"
pdfseparate "$source_pdf" "$tmp_pages_dir/%d.pdf"

# If we can confirm there are multiple cores available, use them.
max_jobs=1
if getconf _NPROCESSORS_ONLN; then
    max_jobs="$(getconf _NPROCESSORS_ONLN)"
fi

find "$tmp_pages_dir" -iname '*.pdf' -print0 |
    xargs -0 -L 1 -P "$max_jobs" clear-page-background

# FIXME Take target PDF as input arg, then name result PDF based on input PDF.
# Using find / sort / xargs because we need to sort input pages numerically.
find "$tmp_pages_dir" -name '*-clear.pdf' -print0 |
    # FIXME Stop hardcoding the number of / chars in the -k param. Count them
    # before constructing this.
    sort -z -n -t / -k5 |
    { cat; printf '%s\0' "$result_pdf"; } |
    xargs -0 -x pdfunite

# FIXME Clean up the processing directory iff we've processed all pages.
# Otherwise we'll want to keep existing pages in place and ignore them, so we
# can fix whatever issues caused some pages to fail then try again.
